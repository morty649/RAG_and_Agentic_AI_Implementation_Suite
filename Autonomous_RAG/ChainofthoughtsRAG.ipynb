{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1606fa7",
   "metadata": {},
   "source": [
    "#### Chain Of Thoughts With RAG\n",
    "What is Chain-of-Thought (CoT) in RAG?\n",
    "\n",
    "CoT reasoning breaks down a complex question into intermediate reasoning steps, and allows retrieval + reflection at each step before answering.\n",
    "\n",
    "User Query\n",
    "   ↓\n",
    "- Step 1: Decompose question → sub-steps (Reason) => Note: they are not sub - questions but reasoning step-by-step\n",
    "- Step 2: Retrieve docs per step (Act)\n",
    "- Step 3: Combine context (Observe)\n",
    "- Step 4: Final answer generation (Reflect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704b5ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maruthienugula/RAG_learnings/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from langchain_core.documents import Document\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import StateGraph, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "277c8cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Prepare Vectorstore\n",
    "# -------------------------------\n",
    "docs = TextLoader(\"research-notes.txt\",encoding=\"utf-8\").load()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "chunks = splitter.split_documents(docs)\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Intializing a simple Hugging face model without any api key\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-mpnet-base-v2\"\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eaa4905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "import os\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "llm = init_chat_model(\"groq:openai/gpt-oss-20b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fcb0f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 2. LangGraph State Definition\n",
    "# -------------------------------\n",
    "class RAGCoTState(BaseModel):\n",
    "    question: str\n",
    "    sub_steps: List[str] = []\n",
    "    retrieved_docs: List[Document] = []\n",
    "    answer: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab3286f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 3. Nodes\n",
    "# -------------------------------\n",
    "\n",
    "# a. Plan sub-questions\n",
    "def plan_steps(state:RAGCoTState)->RAGCoTState:\n",
    "    prompt=f\"Break the question into 2-3 reasoning steps Don't reply with any other things just break them and reply with the broken steps: \\n\\n {state.question}\"\n",
    "    result=llm.invoke(prompt).content\n",
    "    subqs=[line.strip(\"- \") for line in result.split(\"\\n\") if line.strip()]\n",
    "\n",
    "    return state.model_copy(update={\"sub_steps\":subqs}) # model_copy -> takes subqs and copy them into sub_steps : something like super class insertion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1538a846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RAGCoTState(question='what are the additional experiments in Transformer eveluation?', sub_steps=['1. Identify the core question: what additional experiments are performed in Transformer evaluation?', '2. Enumerate the types of experiments beyond standard benchmarks (e.g., ablation studies, hyper‑parameter sweeps, robustness tests, efficiency metrics, transfer‑learning tests, interpretability experiments).', '3. Summarize the categories and specific experiments that are commonly reported in the literature.'], retrieved_docs=[], answer='')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what are the additional experiments in Transformer eveluation?\" #just an example from research-notes.txt which is a company's notes example\n",
    "state = RAGCoTState(question=query)\n",
    "planned_steps_example = plan_steps(state=state)\n",
    "planned_steps_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4eda6ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Retrieve for each step\n",
    "def retrieve_per_step(state:RAGCoTState)-> RAGCoTState:\n",
    "    all_docs=[]\n",
    "    for sub in state.sub_steps:\n",
    "        docs = retriever.invoke(sub)\n",
    "        all_docs.extend(docs)\n",
    "    return state.model_copy(update={\"retrieved_docs\": all_docs})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2a841a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Generate Final Answer\n",
    "def generate_answer(state: RAGCoTState) -> RAGCoTState:\n",
    "    \n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in state.retrieved_docs])\n",
    "    prompt = f\"\"\"\n",
    "You are answering a complex question using reasoning and retrieved documents.\n",
    "\n",
    "Question: {state.question}\n",
    "\n",
    "Relevant Information:\n",
    "{context}\n",
    "\n",
    "Now synthesize a well-reasoned final answer.\n",
    "\"\"\"\n",
    "    result = llm.invoke(prompt).content.strip()\n",
    "    return state.model_copy(update={\"answer\": result})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69a6d106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x13841ffb0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4. LangGraph Graph\n",
    "# -------------------------------\n",
    "builder = StateGraph(RAGCoTState)\n",
    "builder.add_node(\"planner\", plan_steps)\n",
    "builder.add_node(\"retriever\", retrieve_per_step)\n",
    "builder.add_node(\"responder\", generate_answer)\n",
    "\n",
    "builder.set_entry_point(\"planner\")\n",
    "builder.add_edge(\"planner\", \"retriever\")\n",
    "builder.add_edge(\"retriever\", \"responder\")\n",
    "builder.add_edge(\"responder\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da17da77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Reasoning Steps: ['1. Clarify the core evaluation metrics and tasks commonly used for Transformers (e.g., perplexity, accuracy, BLEU).', '2. Identify what is meant by “additional experiments”—i.e., tests beyond the standard metrics, such as ablation studies, robustness checks, or resource efficiency analyses.', '3. Enumerate the specific additional experiments that are typically performed in Transformer evaluation (e.g., layer-wise analysis, attention visualization, adversarial robustness, cross‑domain transfer, hardware profiling).']\n",
      "\n",
      " Final Answer:\n",
      " **Additional Experiments in the Transformer Evaluation (July 2024)**  \n",
      "\n",
      "| # | Experiment | What was tested | Key take‑aways |\n",
      "|---|------------|-----------------|----------------|\n",
      "| **1** | **FlashAttention‑2 integration** | Integrated the FlashAttention‑2 kernel into LLaMA‑2 to accelerate the self‑attention operation. | Latency on long‑context inputs dropped by ~50 % while keeping the same throughput; no accuracy loss. |\n",
      "| **2** | **Chain‑of‑Thought (CoT) prompting** | Compared direct‑answer prompting with CoT and reflective prompting on a suite of logic and math problems. | CoT outperformed direct answering by ~8 % on logic tasks; adding a reflective “check‑your‑work” step gave an extra ~3 % bump. |\n",
      "| **3** | **Retrieval‑augmented experiments** | Hybrid dense‑+‑sparse retrievers were built: (a) Weaviate (graph‑based) vs (b) FAISS + BM25 reranking. | FAISS was faster but had slightly lower recall; Weaviate’s GraphQL filtering helped keep relevant docs, improving precision. |\n",
      "| **4** | **LoRA (Low‑Rank Adaptation) tuning** | Fine‑tuned LLaMA‑2 with a rank‑8 LoRA adapter (dropout = 0.05) via the PEFT library. | GPU memory usage fell by ~60 %, making the model viable on a single A100, with negligible impact on accuracy. |\n",
      "| **5** | **Tool‑augmented prompting** | Combined LangGraph, Wikipedia, and SQL search to create a dynamic RAG pipeline. | Allowed the model to pull fresh data (e.g., customer‑insights from SQL) and verify it against Wikipedia, improving factuality. |\n",
      "| **6** | **Human‑evaluation protocol** | Internal annotators scored fluency, helpfulness, and correctness; GPT‑4 served as a synthetic judge. | Provided a robust, multi‑metric benchmark that captured both subjective and objective quality aspects. |\n",
      "| **7** | **Safety & robustness checks** | Applied Detoxify for toxicity detection, a zero‑shot out‑of‑scope classifier, and adversarial prompt red‑team testing. | Established baseline safety metrics and identified failure modes for future mitigation. |\n",
      "\n",
      "### How these experiments fit into the overall evaluation\n",
      "\n",
      "1. **Efficiency & latency** – FlashAttention‑2 and LoRA tuning directly target inference speed and memory footprint, which are critical for edge deployments (e.g., Raspberry Pi 4, A100 inference).  \n",
      "2. **Reasoning & accuracy** – Chain‑of‑Thought prompting demonstrates a simple prompt‑engineering path to better logical reasoning without architectural changes.  \n",
      "3. **Retrieval & knowledge freshness** – The hybrid dense‑plus‑sparse retrievers and tool‑augmented prompting explore how best to combine static embeddings with live data sources (SQL, Wikipedia).  \n",
      "4. **Human‑centered quality** – The evaluation protocol ensures that improvements in metrics like F1 or accuracy translate into real‑world usefulness.  \n",
      "5. **Safety** – The toxicity and out‑of‑scope filters provide a baseline for responsible deployment, especially when the model is exposed to open‑domain queries.  \n",
      "\n",
      "Together, these experiments extend the core Transformer benchmark (accuracy on TinyImageNet, customer‑support logs, etc.) by probing **runtime performance, reasoning capabilities, retrieval integration, fine‑tuning efficiency, and safety**—all key dimensions for deploying large language models in production.\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 5. Run CoT RAG Agent\n",
    "# -------------------------------\n",
    "from IPython.display import display, Markdown\n",
    "if __name__ == \"__main__\":\n",
    "    query = \"what are the additional experiments in Transformer eveluation?\" #just an example from research-notes.txt which is a company's notes example\n",
    "    state = RAGCoTState(question=query)\n",
    "    final = graph.invoke(state)\n",
    "\n",
    "    print(\"\\n Reasoning Steps:\",final['sub_steps'])\n",
    "    #display(Markdown(final['sub_steps']))\n",
    "    print(\"\\n Final Answer:\\n\",final['answer'])\n",
    "    #display(Markdown(final['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ae59e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Clarify the core evaluation metrics and tasks commonly used for Transformers (e.g., perplexity, accuracy, BLEU).\n",
       "\n",
       "2. Identify what is meant by “additional experiments”—i.e., tests beyond the standard metrics, such as ablation studies, robustness checks, or resource efficiency analyses.\n",
       "\n",
       "3. Enumerate the specific additional experiments that are typically performed in Transformer evaluation (e.g., layer-wise analysis, attention visualization, adversarial robustness, cross‑domain transfer, hardware profiling)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "md_text = \"\\n\\n\".join(final[\"sub_steps\"])\n",
    "display(Markdown(md_text))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78ec9140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Additional Experiments in the Transformer Evaluation (July 2024)**  \n",
       "\n",
       "| # | Experiment | What was tested | Key take‑aways |\n",
       "|---|------------|-----------------|----------------|\n",
       "| **1** | **FlashAttention‑2 integration** | Integrated the FlashAttention‑2 kernel into LLaMA‑2 to accelerate the self‑attention operation. | Latency on long‑context inputs dropped by ~50 % while keeping the same throughput; no accuracy loss. |\n",
       "| **2** | **Chain‑of‑Thought (CoT) prompting** | Compared direct‑answer prompting with CoT and reflective prompting on a suite of logic and math problems. | CoT outperformed direct answering by ~8 % on logic tasks; adding a reflective “check‑your‑work” step gave an extra ~3 % bump. |\n",
       "| **3** | **Retrieval‑augmented experiments** | Hybrid dense‑+‑sparse retrievers were built: (a) Weaviate (graph‑based) vs (b) FAISS + BM25 reranking. | FAISS was faster but had slightly lower recall; Weaviate’s GraphQL filtering helped keep relevant docs, improving precision. |\n",
       "| **4** | **LoRA (Low‑Rank Adaptation) tuning** | Fine‑tuned LLaMA‑2 with a rank‑8 LoRA adapter (dropout = 0.05) via the PEFT library. | GPU memory usage fell by ~60 %, making the model viable on a single A100, with negligible impact on accuracy. |\n",
       "| **5** | **Tool‑augmented prompting** | Combined LangGraph, Wikipedia, and SQL search to create a dynamic RAG pipeline. | Allowed the model to pull fresh data (e.g., customer‑insights from SQL) and verify it against Wikipedia, improving factuality. |\n",
       "| **6** | **Human‑evaluation protocol** | Internal annotators scored fluency, helpfulness, and correctness; GPT‑4 served as a synthetic judge. | Provided a robust, multi‑metric benchmark that captured both subjective and objective quality aspects. |\n",
       "| **7** | **Safety & robustness checks** | Applied Detoxify for toxicity detection, a zero‑shot out‑of‑scope classifier, and adversarial prompt red‑team testing. | Established baseline safety metrics and identified failure modes for future mitigation. |\n",
       "\n",
       "### How these experiments fit into the overall evaluation\n",
       "\n",
       "1. **Efficiency & latency** – FlashAttention‑2 and LoRA tuning directly target inference speed and memory footprint, which are critical for edge deployments (e.g., Raspberry Pi 4, A100 inference).  \n",
       "2. **Reasoning & accuracy** – Chain‑of‑Thought prompting demonstrates a simple prompt‑engineering path to better logical reasoning without architectural changes.  \n",
       "3. **Retrieval & knowledge freshness** – The hybrid dense‑plus‑sparse retrievers and tool‑augmented prompting explore how best to combine static embeddings with live data sources (SQL, Wikipedia).  \n",
       "4. **Human‑centered quality** – The evaluation protocol ensures that improvements in metrics like F1 or accuracy translate into real‑world usefulness.  \n",
       "5. **Safety** – The toxicity and out‑of‑scope filters provide a baseline for responsible deployment, especially when the model is exposed to open‑domain queries.  \n",
       "\n",
       "Together, these experiments extend the core Transformer benchmark (accuracy on TinyImageNet, customer‑support logs, etc.) by probing **runtime performance, reasoning capabilities, retrieval integration, fine‑tuning efficiency, and safety**—all key dimensions for deploying large language models in production."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(final['answer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0129618",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_learnings (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
